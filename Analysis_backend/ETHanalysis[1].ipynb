{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mongopy\n",
      "  Downloading mongopy-0.01.tar.gz (3.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nose (from mongopy)\n",
      "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "Building wheels for collected packages: mongopy\n",
      "  Building wheel for mongopy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mongopy: filename=mongopy-0.1-py3-none-any.whl size=2988 sha256=08b89186cbb389a7721274f852709e0b88cca68ae4cd2bd09de140bcdeab0b31\n",
      "  Stored in directory: /Users/samahita/Library/Caches/pip/wheels/c6/40/d5/9fd62fe0098ab4a90fb61eabeaffa7221bf18c86c7e0685a2f\n",
      "Successfully built mongopy\n",
      "Installing collected packages: nose, mongopy\n",
      "Successfully installed mongopy-0.1 nose-1.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mongopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "# Load variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Get values from environment\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "MONGO_DB = os.getenv(\"MONGO_DB\")\n",
    "MONGO_COLLECTION = os.getenv(\"MONGO_COLLECTION\")\n",
    "\n",
    "# Example connection\n",
    "client = MongoClient(MONGO_URI)\n",
    "\n",
    "# Choose DB and collection\n",
    "db = client[MONGO_DB]\n",
    "collection = db[MONGO_COLLECTION]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        _id  block_number          block_time  \\\n",
      "0  68811f156e21c4e4792e8d64      22983426 2025-07-23 17:42:35   \n",
      "1  68811f166e21c4e4792e8d65      22983426 2025-07-23 17:42:35   \n",
      "2  68811f1e6e21c4e4792e8d66      22983426 2025-07-23 17:42:35   \n",
      "3  68811f206e21c4e4792e8d67      22983426 2025-07-23 17:42:35   \n",
      "4  68811f226e21c4e4792e8d68      22983426 2025-07-23 17:42:35   \n",
      "\n",
      "                                             tx_hash  \\\n",
      "0  a9bad274ed42d321b2f0abf147d2e61f22a9611ed78272...   \n",
      "1  4196e4299599f6e8fad16abb4ea8ee3f3cc39ac4cb5015...   \n",
      "2  24ba43651a8be89131a585af965b4338ef6374a146aff5...   \n",
      "3  70b33b2905672b5bdfdade0be7f0393eab96055400aac8...   \n",
      "4  444dd322cf9f002bd0dfb89ade994675e4db4f2fc39479...   \n",
      "\n",
      "                                         from  \\\n",
      "0  0xb58555FCBa6479FcED7dE1485eB054943a09af7b   \n",
      "1  0xa7565354851c34cffc94F024867bfE814FA5f3c0   \n",
      "2  0xa7565354851c34cffc94F024867bfE814FA5f3c0   \n",
      "3  0xb58555FCBa6479FcED7dE1485eB054943a09af7b   \n",
      "4  0x9E1c7Cc9f4EBF41ef131cCe3B8888EC8E0204Ecd   \n",
      "\n",
      "                                           to    gas_price  max_fee_per_gas  \\\n",
      "0  0x00000000003b3cc22aF3aE1EAc0440BcEe416B40   1597450304              NaN   \n",
      "1  0x917ceE801a67f933F2e6b33fC0cD1ED2d5909D88   1676450304     3.400000e+09   \n",
      "2  0x0000000000001fF3684f28c67538d4D072C22734   1676450304     3.400000e+09   \n",
      "3  0x00000000003b3cc22aF3aE1EAc0440BcEe416B40   1597450304              NaN   \n",
      "4  0x5DDf30555EE9545c8982626B7E3B6F70e5c2635f  31597450304     3.202177e+10   \n",
      "\n",
      "   max_priority_fee_per_gas  nonce  type  \\\n",
      "0                       NaN  88538     0   \n",
      "1              7.900000e+07      8     2   \n",
      "2              7.900000e+07      9     2   \n",
      "3                       NaN  88539     0   \n",
      "4              3.000000e+10    964     2   \n",
      "\n",
      "                                               input      status function  \\\n",
      "0  b\"\\x03\\x9fa\\xd9A\\xd8\\xb4\\xd00\\xb61\\xe0UJGj\\t'\\...  unverified  unknown   \n",
      "1  b\"\\t^\\xa7\\xb3\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\...    verified  approve   \n",
      "2  b'\"\\x13\\xbc\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0...  unverified  unknown   \n",
      "3  b\"\\x05\\x9fa\\xd9A\\xd8\\xb4\\xd00\\xb61\\xa0\\xb8i\\x9...  unverified  unknown   \n",
      "4  b\"P\\x07\\x7f\\xdd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0...  unverified  unknown   \n",
      "\n",
      "                                              params  \n",
      "0                                                NaN  \n",
      "1  {'spender': '0x0000000000001fF3684f28c67538d4D...  \n",
      "2                                                NaN  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Fetch N documents (e.g., 100 for testing)\n",
    "cursor = collection.find().limit(100)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(list(cursor))\n",
    "\n",
    "# Convert block_time if stored as ISO string\n",
    "if \"block_time\" in df.columns:\n",
    "    df[\"block_time\"] = pd.to_datetime(df[\"block_time\"])\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   block_number          block_time  \\\n",
      "0      22983426 2025-07-23 17:42:35   \n",
      "1      22983426 2025-07-23 17:42:35   \n",
      "2      22983426 2025-07-23 17:42:35   \n",
      "3      22983426 2025-07-23 17:42:35   \n",
      "4      22983426 2025-07-23 17:42:35   \n",
      "\n",
      "                                             tx_hash  \\\n",
      "0  a9bad274ed42d321b2f0abf147d2e61f22a9611ed78272...   \n",
      "1  4196e4299599f6e8fad16abb4ea8ee3f3cc39ac4cb5015...   \n",
      "2  24ba43651a8be89131a585af965b4338ef6374a146aff5...   \n",
      "3  70b33b2905672b5bdfdade0be7f0393eab96055400aac8...   \n",
      "4  444dd322cf9f002bd0dfb89ade994675e4db4f2fc39479...   \n",
      "\n",
      "                                         from  \\\n",
      "0  0xb58555FCBa6479FcED7dE1485eB054943a09af7b   \n",
      "1  0xa7565354851c34cffc94F024867bfE814FA5f3c0   \n",
      "2  0xa7565354851c34cffc94F024867bfE814FA5f3c0   \n",
      "3  0xb58555FCBa6479FcED7dE1485eB054943a09af7b   \n",
      "4  0x9E1c7Cc9f4EBF41ef131cCe3B8888EC8E0204Ecd   \n",
      "\n",
      "                                           to  gas_price  max_fee_per_gas  \\\n",
      "0  0x00000000003b3cc22aF3aE1EAc0440BcEe416B40   0.000000              NaN   \n",
      "1  0x917ceE801a67f933F2e6b33fC0cD1ED2d5909D88   0.002633     3.400000e+09   \n",
      "2  0x0000000000001fF3684f28c67538d4D072C22734   0.002633     3.400000e+09   \n",
      "3  0x00000000003b3cc22aF3aE1EAc0440BcEe416B40   0.000000              NaN   \n",
      "4  0x5DDf30555EE9545c8982626B7E3B6F70e5c2635f   1.000000     3.202177e+10   \n",
      "\n",
      "   max_priority_fee_per_gas  nonce  type      status  function  \n",
      "0                       NaN  88538     0  unverified       NaN  \n",
      "1              7.900000e+07      8     2    verified       NaN  \n",
      "2              7.900000e+07      9     2  unverified       NaN  \n",
      "3                       NaN  88539     0  unverified       NaN  \n",
      "4              3.000000e+10    964     2  unverified       NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_keep = [\n",
    "    \"block_number\", \"block_time\", \"tx_hash\", \"from\", \"to\", \n",
    "    \"gas_price\", \"max_fee_per_gas\", \"max_priority_fee_per_gas\", \n",
    "    \"nonce\", \"type\", \"status\", \"function\"\n",
    "]\n",
    "\n",
    "# This will keep only available columns and add missing ones as NaN\n",
    "df = df.reindex(columns=columns_to_keep)\n",
    "\n",
    "\n",
    "df.rename(columns={\"hash\": \"tx_hash\"}, inplace=True)\n",
    "\n",
    "print(df.head()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block_number', 'block_time', 'tx_hash', 'from', 'to', 'gas_price', 'max_fee_per_gas', 'max_priority_fee_per_gas', 'nonce', 'type', 'status', 'function', 'confirmation_delay', 'effective_gas_fee', 'block_utilization']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "df[\"function\"] = df[\"function\"].fillna(\"unknown\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "func_encoder = LabelEncoder()\n",
    "df[\"function_encoded\"] = func_encoder.fit_transform(df[\"function\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"gas_price\", \"effective_gas_fee\", \"block_utilization\", \n",
    "    \"nonce\", \"confirmation_delay\", \"function_encoded\"\n",
    "]\n",
    "target_col = \"gas_price\"   \n",
    "\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "df[feature_cols] = scaler_X.fit_transform(df[feature_cols])\n",
    "df[[target_col]] = scaler_y.fit_transform(df[[target_col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TxDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col, window_size=10):\n",
    "        self.features = df[feature_cols].values\n",
    "        self.targets = df[target_col].values\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.window_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.features[idx:idx+self.window_size]\n",
    "        y = self.targets[idx+self.window_size]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Create dataset & loader\n",
    "dataset = TxDataset(df, feature_cols, target_col, window_size=10)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2):\n",
    "        super(AttentionLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.attention = nn.Linear(hidden_dim*2, 1)   \n",
    "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)               \n",
    "        weights = torch.softmax(self.attention(lstm_out), dim=1)  \n",
    "        context = torch.sum(weights * lstm_out, dim=1)            \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.001180\n",
      "Epoch 2/20, Loss: 0.001528\n",
      "Epoch 3/20, Loss: 0.000720\n",
      "Epoch 4/20, Loss: 0.000962\n",
      "Epoch 5/20, Loss: 0.000696\n",
      "Epoch 6/20, Loss: 0.001656\n",
      "Epoch 7/20, Loss: 0.000731\n",
      "Epoch 8/20, Loss: 0.000846\n",
      "Epoch 9/20, Loss: 0.001185\n",
      "Epoch 10/20, Loss: 0.000533\n",
      "Epoch 11/20, Loss: 0.001734\n",
      "Epoch 12/20, Loss: 0.001276\n",
      "Epoch 13/20, Loss: 0.000390\n",
      "Epoch 14/20, Loss: 0.000908\n",
      "Epoch 15/20, Loss: 0.000725\n",
      "Epoch 16/20, Loss: 0.000295\n",
      "Epoch 17/20, Loss: 0.001253\n",
      "Epoch 18/20, Loss: 0.000466\n",
      "Epoch 19/20, Loss: 0.000441\n",
      "Epoch 20/20, Loss: 0.000773\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AttentionLSTM(input_dim=len(feature_cols)).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device).unsqueeze(1) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Gas Price: [[0.10055843]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_X, _ = dataset[0]  # first sequence\n",
    "    sample_X = sample_X.unsqueeze(0).to(device)  # add batch dim\n",
    "    prediction = model(sample_X).cpu().numpy()\n",
    "\n",
    "    # inverse transform to original gas price scale\n",
    "    predicted_price = scaler_y.inverse_transform(prediction)\n",
    "    print(\"Predicted Next Gas Price:\", predicted_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy write function\n",
    "#difference between alstm and bi\n",
    "#providing graph on simulation and testing for the users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(3, 128, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]   \n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "input_dim = len(feature_cols)   \n",
    "hidden_dim = 128\n",
    "num_layers = 4\n",
    "output_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2416\n",
      "Epoch 2, Loss: 0.2387\n",
      "Epoch 3, Loss: 0.2342\n",
      "Epoch 4, Loss: 0.2387\n",
      "Epoch 5, Loss: 0.2381\n",
      "Epoch 6, Loss: 0.2305\n",
      "Epoch 7, Loss: 0.2351\n",
      "Epoch 8, Loss: 0.2382\n",
      "Epoch 9, Loss: 0.2297\n",
      "Epoch 10, Loss: 0.2331\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005) \n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for X, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "\n",
    "        # reshape to same dimension\n",
    "        outputs = outputs.view(-1)\n",
    "        y = y.view(-1)\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
